---
title: "Untitled"
author: 
- Ana Luzielma \newline
- Jaylhane Nunes \newline
- Raianny Soares
date: "07/02/2022"

header-includes:
  - \usepackage[brazilian]{babel}
  - \usepackage{float}
  - \floatplacement{figure}{H}
  - \usepackage[utf8]{inputenc} 
  - \usepackage{pagecolor}
  - \usepackage{xcolor}
  - \usepackage{indentfirst}
  - \setlength\parindent{22pt}
  - \usepackage{longtable,booktabs}
  #- \usepackage[orientation=landscape,size=custom,width=16,height=9.75,scale=0.5, debug]{beamerposter} 

output: 
  beamer_presentation:
    #toc: TRUE
    theme: "Dresden"
    colortheme: "seagull"
    fonttheme: "structuresmallcapsserif"
    slide_level: 4
    keep_tex: TRUE
    
fontsize: 9 pt
  
---

```{r setup, include=FALSE}
# preparacao do documento

library(knitr)
opts_chunk$set(message=FALSE, 
               warning=FALSE,
               echo = TRUE, 
               eval = TRUE, 
               # quando cache = TRUE, o R soh irah rodar o chunk
               # se houver alguma alteração entre duas compilacoes
               # consecutivas. portanto, se o seu trabalho estiver
               # levando muito tempo para finalizar, altere a configuracao
               # abaixo. apague manualmente as pastas do cache antes de
               # compilar o arquivo pela ultima vez
               results="asis",
               cache = TRUE, 
               dev = "png",
               dpi = 500
               )

# paralelizacao - este código fará com que seu computador
# rode trechos do código em paralelo, de modo a reduzir
# o tempo de processamento necessario

library(tidyverse)
library(tidymodels)
library(lubridate)
library(kableExtra)
library(GGally)

theme_set(theme_light(base_family = "IBMPlexSans"))
```

# Introdução

### Contextualização

Motivadas pelo interesse comum em leitura optamos por realizar a análise de um conjuntos de dados envolvendo livros. 

O conjunto de dados selecionado possui **11.131 observações**, foi gerado por meio de **raspagem** de dados na **API** da plataforma **GoodReads** e disponibilizado por **_Soumik_** no site **Kagle**. 

Nele é possível encontras as seguintes colunas:
```{r, echo=FALSE}
nomes_df_livros <- names(read.csv("./Conjunto de Dados/books.csv",
                                  encoding = "UTF-8",
                                  header = TRUE))
#descricao <- c("Identificação",
#               "Título",
#               "Autores",
#               "Média de Avaliação",
#               "Código ISBN",
#               "Código ISBN13",
#               "Língua original de publicação",
#               "Número de páginas",
#               "Quantidade de Avaliações",
#               "Quantidade de Avaliações Escritas",
#               "Data de publicação",
#               "Editora")

nomes_df_livros <- matrix(nomes_df_livros,ncol = 4)

kable(nomes_df_livros,booktabs= TRUE) %>% 
  kable_styling(latex_options = "HOLD_position", position = "center")
```

Chegamos a um consenso que diversos fatores influenciam na satisfação com a leitura e quisemos investigar se, com os dados disponíveis, seria possível obter um modelo que conseguisse predizer se o livro foi considerado: _ruim_, _bom_ ou _ótimo_ . 

### Uma Ideia Inicial

![](./Imagens/desempenho_xgboost_comparacao.png){width=75%}

Dentre as leituras realizadas sobre as possibilidades de modelos e métodos, percebemos que o XGboost tinha um ótimo desempenho comparado a outros modelos, e que, apesar da variável `average_rating` ser uma variável contínua um método de classificação poderia ser adequado para os nossos objetivos, desde que gerassemos categorias e encaixassemos os intervalos. 

### A Inspiração Final

![](./Imagens/xgboost_juliasilge.png){width=95%, height=90%}

### Indicamos

![](./Imagens/juliasilge_mini.png)
juliasilge.com

- _Agora, à nossa análise!_

# Desenvolvimento

### Engenharia de Dados

A análise exploratória consistiu em:

- Limpeza dos Dados
- Análise Descritiva

Dado os nossos objetivos, percebemos que algumas colunas eram dispensáveis e outras poderiam ser transformadas, de forma que:  

```{r cars, echo=FALSE}
excluidas <- c(nomes_df_livros[1,c(1)],
               nomes_df_livros[2,c(1,2)],
               nomes_df_livros[3,c(1,2,4)])

Transfomadas <- c(nomes_df_livros[1,c(2,3,4)],
                  nomes_df_livros[2,c(4)],
                  "",
                  "")

Geradas <- c("book_rating¹",
             "",
             "prop_text_reviews²",
             "",
             "",
             "")

final <- data.frame(excluidas,Transfomadas,Geradas) %>% 
  rename("Excluídas" = excluidas)

kable(final,booktabs= TRUE) %>% 
  kable_styling(latex_options = "HOLD_position", position = "center")

```

##### _Nosso **MAIOR** desafio durante a análise e a modelagem esteve relacionado a essa fase de engenharia de dados_

### Análise Exploratória

- Para iniciar separamos o conjunto em **treino** e **teste** baseando-nos em 75% das observações e balanceando-as com nossa variável resposta:  `book_rating`. 

```{r, echo=FALSE}
livros <- read.csv("./Conjunto de Dados/books_t.csv",
                   encoding = "UTF-8") %>% 
  mutate_if(is.character,factor) %>%
  mutate(month_publication=factor(month_publication),
         year_publication=factor(year_publication),
         book_rating=factor(book_rating,
                            levels = c("Ótimo","Bom","Ruim")))
```

```{r}
set.seed(1904, kind = "Mersenne-Twister", normal.kind = "Inversion")
livros_split <- initial_split(livros, prop = .75, strata = book_rating)
livros_treino <- training(livros_split)
livros_teste <- testing(livros_split)
```

- Em seguida verificamos a dispersão e correlação entre as variáveis numéricas:

```{r, results="hide", eval=FALSE}
livros_treino %>% 
  select(where(is.numeric)) %>% 
  ggpairs(upper = list(continuous = wrap("cor", method = "spearman")))
```

### Análise Exploratória

```{r, echo=FALSE}
livros_treino %>% 
  select(where(is.numeric)) %>% 
  ggpairs(upper = list(continuous = wrap("cor", method = "spearman")))
```

### Análise Exploratória

Com o resultado anterior percebemos que: 

- Correlação forte entre `text_reviews_count` e `ratings_count`. 
- Pensamos em gerar uma variável que considerasse a quantidade de `text_reviews_count`,pois consideramos que isso seria um indicativo importante para nossa resposta e chegamos a uma variável que correspondesse a proporção entre `text_reviews_count`/`ratings_count`

```{r}
livros_treino <- livros_treino %>% 
  mutate(prop_text_reviews = text_reviews_count / ratings_count) %>% 
  select(-text_reviews_count)

cor(livros_treino$prop_text_reviews,livros_treino$ratings_count,
    use = "complete", method = "spearman")
```

- A correlação entre `prop_text_reviews`e `ratings_count` não indicou multicolinearidade, então prosseguimos com essa variável como preditora.

### Continuando a Análise Exploratória e Descritiva

```{r, echo=FALSE}
livros_treino %>% 
  select(where(is.numeric),book_rating) %>% 
  pivot_longer(-book_rating) %>% 
  ggplot(.,aes(fill = book_rating)) +
  geom_boxplot(aes(y=value)) +
  facet_wrap(~ name, scales = "free") +
  labs(x="",
       y="Valor",
       fill = "Classificação\ndo Livro",
       title = "Boxplot das variáveis por classificação do livro")+
  scale_fill_viridis_d()
```

### Continuando a Análise Exploratória e Descritiva

```{r, echo=FALSE}
livros_treino %>% 
  mutate(book_rating = book_rating == "Ótimo") %>% 
  group_by(
    mes = month_publication,
    ano = year_publication
  ) %>% 
  summarise(book_rating = mean(book_rating)) %>% 
  ggplot(aes(mes,ano, fill = book_rating)) + 
  geom_tile(alpha = .75) + 
  scale_fill_viridis_c(labels = scales::percent) + 
  labs(fill = "% livros ótimos" , x="Mês", y="Ano",
       title = "Escala dos livros avaliados como: ÓTIMO")+
  theme(legend.position = "right")
```

### Mais gráficos =)

```{r, echo=FALSE}
livros_treino %>%  
  group_by(
    mes = month_publication,
    ano = year_publication
  ) %>% 
  count() %>% 
  ggplot(aes(n,ano, fill=mes))+
  geom_col()+
  geom_hline(yintercept = "1986", color = "blue", lty=2)+
  geom_hline(yintercept = "2008", color = "blue", lty=2)+
  theme(panel.border = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor = element_blank())+
  labs(x = "Quantidade Publicações",
       y = "Ano",
       fill = "Mês",
       title = "Quantidade de Publicações por Ano")+
  scale_fill_viridis_d()
```

### Definindo Filtros

```{r, echo=FALSE}
gridExtra::grid.arrange(ncol=2,
                        livros_treino %>% 
  ggplot(aes(x=book_age)) +
  geom_histogram(bins=30)+
  geom_vline(xintercept = quantile(livros_treino$book_age),
             color="green", lty=2)+
  labs(title = "Histograma book_age",
       x="",
       y="")
,
livros_treino %>% 
  ggplot(aes(x=num_pages)) +
  geom_histogram(bins=30)+
  geom_vline(xintercept = quantile(livros_treino$num_pages),
             color="green", lty=2)+
  labs(title = "Histograma num_pages",
       x="",
       y="")
,
livros_treino %>% 
  ggplot(aes(x=ratings_count)) +
  geom_histogram(bins=30)+
  geom_vline(xintercept = quantile(livros_treino$ratings_count),
             color="green", lty=2)+
  labs(title = "Histograma ratings_count",
       x="",
       y="")
,
livros_treino %>% 
  ggplot(aes(x=prop_text_reviews)) +
  geom_histogram(bins=30)+
  geom_vline(xintercept = quantile(livros_treino$prop_text_reviews, na.rm = TRUE),
             color="green", lty=2)+
  labs(title = "Histograma prop_text_reviews",
       x="",
       y="")
)
```

### Novo boxplot com filtros aplicados

```{r, echo=FALSE}
livros_treino %>% 
  filter(book_age<40) %>% 
  filter(num_pages<1000) %>%
  filter(ratings_count<1000) %>% 
  select(where(is.numeric),book_rating) %>% 
  pivot_longer(-book_rating) %>% 
  ggplot(.,aes(fill = book_rating)) +
  geom_boxplot(aes(y=value)) +
  facet_wrap(~ name, scales = "free") +
  labs(x="",
       y="Valor",
       fill = "Classificação\ndo Livro",
       title = "Boxplot das variáveis por classificação do livro")+
  scale_fill_viridis_d()
```

## A modelagem

