---
title: "Modelagem XGBOOST para a classificação de avaliações de livros"
author: 
- Ana Luzielma Campos \newline
- Jaylhane Nunes \newline
- Raianny Soares
date: "07/02/2022"

header-includes:
  - \usepackage[brazilian]{babel}
  - \usepackage{float}
  - \floatplacement{figure}{H}
  - \usepackage[utf8]{inputenc} 
  - \usepackage{pagecolor}
  - \usepackage{xcolor}
  - \usepackage{indentfirst}
  - \setlength\parindent{22pt}
  - \usepackage{longtable,booktabs}
  #- \usepackage[orientation=landscape,size=custom,width=16,height=9.75,scale=0.5, debug]{beamerposter} 

output: 
  beamer_presentation:
    #toc: TRUE
    theme: "Dresden"
    colortheme: "seagull"
    fonttheme: "structuresmallcapsserif"
    slide_level: 4
    keep_tex: TRUE
    
fontsize: 9 pt
  
---

```{r setup, include=FALSE}
# preparacao do documento

library(knitr)
opts_chunk$set(message=FALSE, 
               warning=FALSE,
               echo = TRUE, 
               eval = TRUE, 
               # quando cache = TRUE, o R soh irah rodar o chunk
               # se houver alguma alteração entre duas compilacoes
               # consecutivas. portanto, se o seu trabalho estiver
               # levando muito tempo para finalizar, altere a configuracao
               # abaixo. apague manualmente as pastas do cache antes de
               # compilar o arquivo pela ultima vez
               results="asis",
               cache = TRUE, 
               dev = "png",
               dpi = 500,
               fig.height = 4,
               fig.width = 6
               )

options(digits = 4)

# paralelizacao - este código fará com que seu computador
# rode trechos do código em paralelo, de modo a reduzir
# o tempo de processamento necessario

library(tidyverse)
library(tidymodels)
library(lubridate)
library(kableExtra)
library(GGally)

theme_set(theme_light(base_family = "IBMPlexSans"))
```

# Introdução

### Contextualização

Motivadas pelo interesse comum em leitura optamos por realizar a análise de um conjuntos de dados envolvendo livros. 

O conjunto de dados selecionado possui **11.131 observações**, foi gerado por meio de **raspagem** de dados na **API** da plataforma **GoodReads** e disponibilizado por **_Soumik_** no site **Kagle**. 

Nele é possível encontrar as 12 colunas seguintes:
```{r, echo=FALSE}
nomes_df_livros <- names(read.csv("./Conjunto de Dados/books.csv",
                                  encoding = "UTF-8",
                                  header = TRUE))
#descricao <- c("Identificação",
#               "Título",
#               "Autores",
#               "Média de Avaliação",
#               "Código ISBN",
#               "Código ISBN13",
#               "Língua original de publicação",
#               "Número de páginas",
#               "Quantidade de Avaliações",
#               "Quantidade de Avaliações Escritas",
#               "Data de publicação",
#               "Editora")

nomes_df_livros <- matrix(nomes_df_livros,ncol = 4)

kable(nomes_df_livros,booktabs= TRUE) %>% 
  kable_styling(latex_options = "HOLD_position", position = "center")
```

Chegamos a um consenso que diversos fatores influenciam na satisfação com a leitura e quisemos investigar se, com os dados disponíveis, seria possível obter um modelo que conseguisse predizer se o livro foi considerado: _ruim_, _bom_ ou _ótimo_ . 

### Uma Ideia Inicial

![Vishal Morde, 2019 - XGBoost Algorithm: Long May She Reign!](./Imagens/desempenho_xgboost_comparacao.png){width=75%}

Dentre as possibilidades percebemos que o **XGboost** tem um ótimo desempenho comparado a outros e que, apesar da nossa variável de avaliação ser uma variável contínua, um método de classificação poderia ser adequado, desde que encaixássemos intervalos em categorias. 

### A Inspiração Final

![](./Imagens/xgboost_juliasilge.png){width=95%, height=90%}

### Indicamos

![](./Imagens/juliasilge_mini.png)
juliasilge.com

- _Agora, à nossa análise!_

# Desenvolvimento

### Engenharia de Dados

A análise exploratória consistiu em:

- Limpeza dos Dados
- Análise Descritiva

Dado os nossos objetivos percebemos que algumas colunas eram dispensáveis e outras poderiam ser transformadas, de forma que:  

```{r cars, echo=FALSE}
excluidas <- c(nomes_df_livros[1,c(1)],
               nomes_df_livros[2,c(1,2)],
               nomes_df_livros[3,c(1,2,4)])

Transfomadas <- c(nomes_df_livros[1,c(2,3,4)],
                  nomes_df_livros[2,c(4)],
                  "",
                  "")

Geradas <- c("book_rating¹",
             "",
             "prop_text_reviews²",
             "book_age",
             "",
             "")

final <- data.frame(excluidas,Transfomadas,Geradas) %>% 
  rename("Excluídas" = excluidas)

kable(final,booktabs= TRUE) %>% 
  kable_styling(latex_options = "HOLD_position", position = "center")

```

##### _Nosso **MAIOR** desafio durante a análise e a modelagem esteve relacionado a essa fase de engenharia de dados_

### Análise Exploratória

- Para iniciar separamos o conjunto em **treino** e **teste** baseando-nos em 75% das observações e balanceando-as com nossa variável resposta:  `book_rating`. 

```{r, echo=FALSE}
livros <- read.csv("./Conjunto de Dados/books_t.csv",
                   encoding = "UTF-8") %>% 
  mutate_if(is.character,factor) %>%
  mutate(month_publication=factor(month_publication),
         year_publication=factor(year_publication),
         book_rating=factor(book_rating,
                            levels = c("Ótimo","Bom","Ruim")))
```

```{r}
set.seed(1904, kind = "Mersenne-Twister", normal.kind = "Inversion")
livros_split <- initial_split(livros, prop = .75, strata = book_rating)
livros_treino <- training(livros_split)
livros_teste <- testing(livros_split)
```

- Em seguida verificamos a dispersão e correlação entre as variáveis numéricas:

```{r, results="hide", eval=FALSE}
livros_treino %>% 
  select(where(is.numeric)) %>% 
  ggpairs(upper = list(continuous = wrap("cor", method = "spearman")))
```

### Análise Exploratória

```{r, echo=FALSE}
livros_treino %>% 
  select(where(is.numeric)) %>% 
  ggpairs(upper = list(continuous = wrap("cor", method = "spearman")))
```

### Análise Exploratória

Com o resultado anterior percebemos que: 

- Correlação forte entre `text_reviews_count` e `ratings_count`. 
- Seria necessário descartar `text_reviews_count` devido riscos de multicolineariedade, mas como consideramos as avaliações escritas relevantes para as categorias _ruim_ e _ótimo_ usamos a proporção entre `text_reviews_count`/`ratings_count`. 

```{r}
livros_treino <- livros_treino %>% 
  mutate(prop_text_reviews = text_reviews_count / ratings_count) %>% 
  select(-text_reviews_count)

cor(livros_treino$prop_text_reviews,livros_treino$ratings_count,
    use = "complete", method = "spearman")
```

- A correlação entre `prop_text_reviews` e `ratings_count` não indicou multicolinearidade, então prosseguimos com essa variável como preditora.

### Continuando a Análise Exploratória e Descritiva

```{r, echo=FALSE}
livros_treino %>% 
  select(where(is.numeric),book_rating) %>% 
  pivot_longer(-book_rating) %>% 
  ggplot(.,aes(fill = book_rating)) +
  geom_boxplot(aes(y=value),alpha=.75) +
  facet_wrap(~ name, scales = "free") +
  labs(x="",
       y="Valor",
       fill = "Classificação\ndo Livro",
       title = "Boxplot das variáveis por classificação do livro")+
  scale_fill_viridis_d()
```

### Conferindo aspectos que consideramos importantes

```{r, echo=FALSE}
livros_treino %>% 
  mutate(book_rating = book_rating == "Ótimo") %>% 
  group_by(
    mes = month_publication,
    ano = year_publication
  ) %>% 
  summarise(book_rating = mean(book_rating)) %>% 
  ggplot(aes(mes,ano, fill = book_rating)) + 
  geom_tile(alpha = .75) + 
  scale_fill_viridis_c(labels = scales::percent, direction = -1) + 
  labs(fill = "% livros ótimos" , x="Mês", y="Ano",
       title = "Escala dos livros avaliados como: ÓTIMO")+
  theme(legend.position = "right")
```

### Mais gráficos =)

```{r, echo=FALSE}
livros_treino %>%  
  group_by(
    mes = month_publication,
    ano = year_publication
  ) %>% 
  count() %>% 
  ggplot(aes(n,ano, fill=mes))+
  geom_col()+
  geom_hline(yintercept = "1986", color = "blue", lty=2)+
  geom_hline(yintercept = "2008", color = "blue", lty=2)+
  theme(panel.border = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor = element_blank())+
  labs(x = "Quantidade Publicações",
       y = "Ano",
       fill = "Mês",
       title = "Quantidade de Publicações por Ano")+
  scale_color_brewer()
```

### Definindo Filtros

```{r, echo=FALSE}
gridExtra::grid.arrange(ncol=2,
                        livros_treino %>% 
  ggplot(aes(x=book_age)) +
  geom_histogram(bins=30)+
  geom_vline(xintercept = quantile(livros_treino$book_age),
             color="green", lty=2)+
  labs(title = "Histograma book_age",
       x="",
       y="")
,
livros_treino %>% 
  ggplot(aes(x=num_pages)) +
  geom_histogram(bins=30)+
  geom_vline(xintercept = quantile(livros_treino$num_pages),
             color="green", lty=2)+
  labs(title = "Histograma num_pages",
       x="",
       y="")
,
livros_treino %>% 
  ggplot(aes(x=ratings_count)) +
  geom_histogram(bins=30)+
  geom_vline(xintercept = quantile(livros_treino$ratings_count),
             color="green", lty=2)+
  labs(title = "Histograma ratings_count",
       x="",
       y="")
,
livros_treino %>% 
  ggplot(aes(x=prop_text_reviews)) +
  geom_histogram(bins=30)+
  geom_vline(xintercept = quantile(livros_treino$prop_text_reviews,
                                   na.rm = TRUE),
             color="green", lty=2)+
  geom_vline(xintercept = 1,
             color="green", lty=2)+
  labs(title = "Histograma prop_text_reviews",
       x="",
       y="")
)
```

### Novo boxplot com filtros aplicados

```{r, echo=FALSE}
livros_treino %>% 
  filter(book_age<40) %>% 
  filter(num_pages<1000) %>%
  filter(ratings_count<1000) %>% 
  select(where(is.numeric),book_rating) %>% 
  pivot_longer(-book_rating) %>% 
  ggplot(.,aes(fill = book_rating)) +
  geom_boxplot(aes(y=value), alpha=.75) +
  facet_wrap(~ name, scales = "free") +
  labs(x="",
       y="Valor",
       fill = "Classificação\ndo Livro",
       title = "Boxplot das variáveis por classificação do livro")+
  scale_fill_viridis_d()
```

## A modelagem


- Com as análises identificamos mudanças necessárias no conjunto de dados, demandando nova divisão em **treino** e **teste**. Os filtros aplicados foram:

```{r, echo=FALSE}
livros <- read.csv("./Conjunto de Dados/books_t.csv",
                   encoding = "UTF-8") %>% 
  mutate(publication_date=as.Date(publication_date),  
         prop_text_reviews = text_reviews_count / ratings_count,
         prop_text_reviews = ifelse(prop_text_reviews %in% c(NaN,Inf),
                                    0, prop_text_reviews),
         book_rating=factor(book_rating,
                            levels = c("Ótimo","Bom","Ruim"))) %>% 
  select(-month_publication, -year_publication, -text_reviews_count) %>% 
  filter(book_age<40) %>% 
  filter(num_pages<1000) %>% 
  filter(ratings_count<1000)

#####Separando Treino e Teste#####

set.seed(1904, kind = "Mersenne-Twister", normal.kind = "Inversion")

livros_split <- initial_split(livros, prop = .75, strata = book_rating)

livros_treino <- training(livros_split)

livros_teste <- testing(livros_split)

filtros <- data.frame(c("book_age","num_pages","rating_count","prop_text_reviews"),
                      c("<40","<1000","<1000","Nenhum"))

names(filtros) <- c("Variável","Filtro")

kable(filtros,booktabs= TRUE) %>% 
  kable_styling(latex_options = "HOLD_position", position = "center")

```

- Posteriormente criamos métricas e _folds_ que serão utilizadas para _tunar_ o módelo:

```{r}
livros_metricas <- metric_set(accuracy, roc_auc, mn_log_loss)

set.seed(1989)
livros_folds <- vfold_cv(livros_treino, strata = book_rating, v=10)
```

- E em seguida as demais etapas da modelagem:

### Pré-Processamento de Dados

```{r}
livros_rec <- recipe(book_rating ~ ., data = livros_treino) %>%
  themis::step_downsample(book_rating) %>% 
  step_date(publication_date, features = c("month"), 
            keep_original_cols = FALSE) %>%
  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
  step_zv(all_predictors()) %>% 
  step_normalize(all_numeric_predictors())%>% 
  prep()

```

### Grid de Procura e de Parada antecipada

```{r}
stopping_spec <-
  boost_tree(
    trees = 500,
    mtry = tune(),
    learn_rate = tune(),
    stop_iter = tune()
  ) %>%
  set_engine("xgboost", validation = 0.2) %>%
  set_mode("classification")
stopping_grid <-
  grid_latin_hypercube(
    mtry(range = c(5, 18)),
    learn_rate(range = c(-5, -1)), 
    stop_iter(range = c(10, 50)), 
    size = 10
  )
early_stop_wf <- workflow(livros_rec, stopping_spec)
```

#### Definido os grids de procura e parada, é hora de **TUNAR** o modelo! 

```{r}
doParallel::registerDoParallel()
set.seed(2022)
stopping_rs <- tune_grid(
  early_stop_wf,
  livros_folds,
  grid = stopping_grid,
  metrics = livros_metricas
)
```

## Resultados

### Interações e Taxa de Aprendizagem

```{r, echo=FALSE}
autoplot(stopping_rs)
```

### Avaliação do modelo

- Avaliando o melhor resultado de acordo com **mn_log_loss**, pois é com ele que acompanhamos a capacidade de aprendizagem do modelo:
```{r, results='hide', eval=FALSE}
show_best(stopping_rs, metric = "mn_log_loss")
```

```{r, echo=FALSE}
melhores <- show_best(stopping_rs, metric = "mn_log_loss")

kable(melhores[,c(1,2,3,6,7,8,9)],booktabs= TRUE) %>% 
  kable_styling(latex_options = "HOLD_position", position = "center")
```

- Em seguida realizamos o modelo final e avaliamos as demais métricas:

```{r, results='hide'}
stopping_fit <- early_stop_wf %>%
  finalize_workflow(select_best(stopping_rs, "mn_log_loss")) %>%
  last_fit(livros_split)

collect_metrics(stopping_fit)
```

```{r, echo=FALSE}
kable(collect_metrics(stopping_fit),booktabs= TRUE) %>% 
  kable_styling(latex_options = "HOLD_position", position = "center")
```

### Variáveis VIP

```{r, echo=FALSE}
library(vip)

extract_workflow(stopping_fit) %>%
  extract_fit_parsnip() %>%
  vip(num_features = 15, geom = "point")+
  labs(title = "Variáveis mais importantes no modelo",
       x = "Importância")
```

### _Heatmap_

```{r, echo=FALSE}
collect_predictions(stopping_fit) %>%
  conf_mat(book_rating, .pred_class) %>%
  autoplot(type = "heatmap")+
  labs(title = "Mapa de Calor das Predições",
       x = "Verdadeiro",
       y = "Predição")
```

### Avaliando a Curva ROC

```{r, echo=FALSE}
collect_predictions(stopping_fit, summarize = FALSE) %>%
  roc_curve(book_rating, .pred_class:.pred_Ruim) %>%
  ggplot(aes(1 - specificity, sensitivity, color = .level)) +
  geom_abline(lty = 2, color = "gray80", size = 1.5) +
  geom_path(alpha = 0.8, size = 1) +
  coord_equal() +
  labs(color = NULL,
       title =  "Curva ROC Modelo Final",
       x="1 - Especificidade",
       y="Sensibilidade")
```

# Conclusão

### Se o modelo disser que o livro é ÓTIMO, desconfie...

- Algumas métricas:

```{r, echo=FALSE}
## Verdadeiro positivo
senbilidade_geral <- collect_predictions(stopping_fit) %>% 
  sens(book_rating, .pred_class)

## Verdadeiro negativo
especificidade_geral <- collect_predictions(stopping_fit) %>% 
  spec(book_rating, .pred_class)

sens_e_spec_categorias <- collect_predictions(stopping_fit, summarize = FALSE) %>%
  roc_curve(book_rating, .pred_class:.pred_Ruim) %>% 
  group_by(.level) %>% 
  summarise(mean_sens=mean(sensitivity),
            mean_spec=mean(specificity))

kable(senbilidade_geral,booktabs= TRUE) %>% 
  kable_styling(latex_options = "HOLD_position", position = "center")

kable(especificidade_geral,booktabs= TRUE) %>% 
  kable_styling(latex_options = "HOLD_position", position = "center")

kable(sens_e_spec_categorias,booktabs= TRUE) %>% 
  kable_styling(latex_options = "HOLD_position", position = "center")
```

### Mais algumas considerações...

- A parte da engenharia de dados, como já comentada, além de desafiadora realiza importante papel na qualidade do modelo

- Algumas mudanças poderiam melhorar o modelo, tais como: 
    - uma melhora na limpeza dos dados, removendo ainda mais outliers;
    - melhor definição nos níveis e categorias das variáveis preditoras;
    - variáveis preditoras mais informativas e com mais distinção entre os níveis. 
    
- Por fim, não consideramos satisfatório a capacidade preditora do modelo e concluímos que a melhor forma de saber se um livro é _ótimo_, _bom_ ou _ruim_, é lendo-o. ;) 

### Referências:

- MORDE, Vishal. **XGBoost Algorithm: Long May She Reign!** - Abril, 2019. Publicado em _Towards Data Science_. Disponível em: [https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d ](https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d)

- SILGE, Julia. **Tune xgboost models with early stopping to predict shelter animal status** - Agosto, 2021. Publicado em Julia Silge. Disponível em: [https://juliasilge.com/blog/shelter-animals/](https://juliasilge.com/blog/shelter-animals/)

- R Core Team (2021). **R:_A language and environment for statistical
  computing_** . R Foundation for Statistical Computing, Vienna, Austria.
  URL https://www.R-project.org/.

- SOUMIK . **Goodreads-books _comprehensive list of books listed in goodreads_** - Maio, 2019. Publicado em Kagle. Disponível em: [https://www.kaggle.com/jealousleopard/goodreadsbooks](https://www.kaggle.com/jealousleopard/goodreadsbooks)